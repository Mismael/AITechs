{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 01: Load lib modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 02: Load CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/cifar-100-python/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46a7d7717b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcifar_dataset_label_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./datasets/cifar-100-python/meta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Load Training Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcifar_dataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_dataset_train_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcifar_dataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_dataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Load Testing Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/cifar-100-python/train'"
     ]
    }
   ],
   "source": [
    "#download https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
    "#Directories \n",
    "cifar_dataset_train_dir = \"./datasets/cifar-100-python/train\"\n",
    "cifar_dataset_test_dir = \"./datasets/cifar-100-python/test\"\n",
    "cifar_dataset_label_dir = \"./datasets/cifar-100-python/meta\"\n",
    "#Load Training Set\n",
    "cifar_dataset_train = open(cifar_dataset_train_dir, 'rb')\n",
    "cifar_dataset_train = pickle.load(cifar_dataset_train, encoding='bytes')\n",
    "#Load Testing Set\n",
    "cifar_dataset_test = open(cifar_dataset_test_dir, 'rb')\n",
    "cifar_dataset_test = pickle.load(cifar_dataset_test, encoding='bytes')\n",
    "#Load Labels\n",
    "cifar_dataset_label = open(cifar_dataset_label_dir, 'rb')\n",
    "cifar_dataset_label = pickle.load(cifar_dataset_label, encoding='bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 03: Check data content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dataset Labels (Super Class: coarse, Sub Class: fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'fine_label_names'\n",
      "b'coarse_label_names'\n"
     ]
    }
   ],
   "source": [
    "for keys in cifar_dataset_label:\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Super Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'aquatic_mammals',\n",
       " b'fish',\n",
       " b'flowers',\n",
       " b'food_containers',\n",
       " b'fruit_and_vegetables',\n",
       " b'household_electrical_devices',\n",
       " b'household_furniture',\n",
       " b'insects',\n",
       " b'large_carnivores',\n",
       " b'large_man-made_outdoor_things',\n",
       " b'large_natural_outdoor_scenes',\n",
       " b'large_omnivores_and_herbivores',\n",
       " b'medium_mammals',\n",
       " b'non-insect_invertebrates',\n",
       " b'people',\n",
       " b'reptiles',\n",
       " b'small_mammals',\n",
       " b'trees',\n",
       " b'vehicles_1',\n",
       " b'vehicles_2']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dataset_label.get(b'coarse_label_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sub Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Labels: \",len(cifar_dataset_label.get(b'fine_label_names')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 04: Visualize, Encode and Load to List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dictionary Keys (for both train and test set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'batch_label'\n",
      "b'fine_labels'\n",
      "b'data'\n",
      "b'filenames'\n",
      "b'coarse_labels'\n"
     ]
    }
   ],
   "source": [
    "for keys in cifar_dataset_train:\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visualize Sample Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Label:  116\n",
      "File Name:  b'bos_taurus_s_000507.png'\n",
      "11\n",
      "b'large_omnivores_and_herbivores'\n",
      "19\n",
      "b'cattle'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e4308b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indx = 0\n",
    "##Reshaping\n",
    "data = cifar_dataset_train.get(b'data')[indx].reshape(3, 1024).T\n",
    "colored_image = data.reshape(32,32,3)\n",
    "#show Image\n",
    "plt.imshow(colored_image)\n",
    "#Print Batch Label\n",
    "print(\"Batch Label: \",cifar_dataset_train.get(b'batch_label')[indx])\n",
    "#Print File Name\n",
    "print(\"File Name: \",cifar_dataset_train.get(b'filenames')[indx])\n",
    "#Print Super Class Name\n",
    "print(cifar_dataset_train.get(b'coarse_labels')[indx])\n",
    "print(cifar_dataset_label.get(b'coarse_label_names')[cifar_dataset_train.get(b'coarse_labels')[indx]])\n",
    "#Print SubClass Name\n",
    "print(cifar_dataset_train.get(b'fine_labels')[indx])\n",
    "print(cifar_dataset_label.get(b'fine_label_names')[cifar_dataset_train.get(b'fine_labels')[indx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reshaping and Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_loaditems(set_idx, item_idx):\n",
    "    if (set_idx == 0): #Training set\n",
    "        #get row of data\n",
    "        data = cifar_dataset_train.get(b'data')[item_idx]\n",
    "        #Super Class Name indx and lable\n",
    "        super_class_idx = cifar_dataset_train.get(b'coarse_labels')[item_idx]\n",
    "        super_class_lbl = cifar_dataset_label.get(b'coarse_label_names')[cifar_dataset_train.get(b'coarse_labels')[item_idx]]\n",
    "        #SubClass Name indx and lable\n",
    "        sub_class_idx = cifar_dataset_train.get(b'fine_labels')[item_idx]\n",
    "        sub_class_lbl = cifar_dataset_label.get(b'fine_label_names')[cifar_dataset_train.get(b'fine_labels')[item_idx]]\n",
    "    elif (set_idx == 1): #Testing set\n",
    "        #get row of data\n",
    "        data = cifar_dataset_test.get(b'data')[indx]\n",
    "        #Super Class Name indx and lable\n",
    "        super_class_idx = cifar_dataset_test.get(b'coarse_labels')[indx]\n",
    "        super_class_lbl = cifar_dataset_label.get(b'coarse_label_names')[cifar_dataset_test.get(b'coarse_labels')[indx]]\n",
    "        #SubClass Name indx and lable\n",
    "        sub_class_idx = cifar_dataset_test.get(b'fine_labels')[indx]\n",
    "        sub_class_lbl = cifar_dataset_label.get(b'fine_label_names')[cifar_dataset_test.get(b'fine_labels')[indx]]\n",
    "\n",
    "    return data, super_class_idx, super_class_lbl, sub_class_idx, sub_class_lbl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    x_train, y_train = [],[]\n",
    "    x_test, y_test = [],[]\n",
    "    nb_classes = 100\n",
    "    \n",
    "    \n",
    "    for i in range(len(cifar_dataset_train.get(b'data'))):\n",
    "        colored_image, _, _, sub_class_idx, _ = cifar_loaditems(0, i)\n",
    "        x_train.append(colored_image)\n",
    "        y_train.append(sub_class_idx)\n",
    "    \n",
    "    \n",
    "    targets = np.array([y_train]).reshape(-1)\n",
    "    y_train = np.eye(nb_classes)[targets]\n",
    "        \n",
    "    for i in range(len(cifar_dataset_test.get(b'data'))):\n",
    "        colored_image, _, _, sub_class_idx, _ = cifar_loaditems(1, i) \n",
    "        x_test.append(colored_image)\n",
    "        y_test.append(sub_class_idx)\n",
    "        \n",
    "    \n",
    "    targets = np.array([y_test]).reshape(-1)\n",
    "    y_test = np.eye(nb_classes)[targets]\n",
    "        \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsize = 32\n",
    "channels = 3\n",
    "\n",
    "\n",
    "# Placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None,inputsize*inputsize*3], name='X')\n",
    "x_image = tf.reshape(x, [-1, 32, 32, 3])\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None,100], name='y_tr')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.elu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 128 and 1024 for 'fc2_2/MatMul' (op: 'MatMul') with input shapes: [?,128], [1024,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 128 and 1024 for 'fc2_2/MatMul' (op: 'MatMul') with input shapes: [?,128], [1024,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-57efc32a8d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mlayer_fc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_fc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_relu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fc2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# RelU layer 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-fefe3e1df54a>\u001b[0m in \u001b[0;36mnew_fc_layer\u001b[0;34m(input, num_inputs, num_outputs, name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Multiply the input and weights, and then add the bias-values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2122\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4277\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4278\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4280\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 128 and 1024 for 'fc2_2/MatMul' (op: 'MatMul') with input shapes: [?,128], [1024,512]."
     ]
    }
   ],
   "source": [
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=3, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu2, [-1, num_features])\n",
    "\n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
    "\n",
    "\n",
    "layer_fc2 = new_fc_layer(layer_relu3, num_inputs=num_features, num_outputs=512, name=\"fc2\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu4 = new_relu_layer(layer_fc2, name=\"relu4\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc3 = new_fc_layer(input=layer_relu4, num_inputs=512, num_outputs= 100, name=\"fc3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc3)\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc3, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        batch_increamenter = 0\n",
    "        for batch in range(0, int(50000/batch_size)):\n",
    "            \n",
    "            # Get a batch of images and labels\n",
    "            x_batch, y_true_batch = x_train [0+batch_increamenter : 32+batch_increamenter], y_train [0+batch_increamenter : 32+batch_increamenter]\n",
    "           \n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(50000/batch_size) + batch)\n",
    "            \n",
    "            batch_increamenter += 32\n",
    "        \n",
    "        \n",
    "        train_accuracy /= int(50000/batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:x_test, y_true:y_test})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
